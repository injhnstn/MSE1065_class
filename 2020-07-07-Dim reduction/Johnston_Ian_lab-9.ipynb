{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn packages - model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#sklearn packages - metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>C</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mn</th>\n",
       "      <th>P</th>\n",
       "      <th>S</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Mo</th>\n",
       "      <th>N</th>\n",
       "      <th>...</th>\n",
       "      <th>Al</th>\n",
       "      <th>Ti</th>\n",
       "      <th>V</th>\n",
       "      <th>B</th>\n",
       "      <th>Th</th>\n",
       "      <th>I</th>\n",
       "      <th>U</th>\n",
       "      <th>Ve</th>\n",
       "      <th>Strain</th>\n",
       "      <th>TCL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.019</td>\n",
       "      <td>17.33</td>\n",
       "      <td>10.62</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.013</td>\n",
       "      <td>16.95</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.001</td>\n",
       "      <td>17.40</td>\n",
       "      <td>11.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.001</td>\n",
       "      <td>17.55</td>\n",
       "      <td>12.95</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023</td>\n",
       "      <td>16.28</td>\n",
       "      <td>10.15</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.      C    Si    Mn      P      S     Cr     Ni    Mo      N  ...    Al  \\\n",
       "0    1  0.010  0.48  1.61  0.024  0.019  17.33  10.62  2.09  0.060  ...  0.02   \n",
       "1    2  0.011  0.58  1.06  0.032  0.013  16.95  10.50  2.15  0.078  ...  0.02   \n",
       "2    3  0.010  0.46  1.09  0.021  0.001  17.40  11.50  2.88  0.105  ...  0.02   \n",
       "3    4  0.010  0.51  1.60  0.021  0.001  17.55  12.95  2.76  0.113  ...  0.02   \n",
       "4    5  0.012  0.46  1.54  0.027  0.023  16.28  10.15  2.06  0.098  ...  0.02   \n",
       "\n",
       "    Ti    V    B    Th    I     U    Ve  Strain  TCL  \n",
       "0  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  1.5  \n",
       "1  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  1.1  \n",
       "2  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  0.9  \n",
       "3  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  3.7  \n",
       "4  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  1.5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data-1.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487, 21) (487,)\n",
      "The number of missing x values is: 0\n",
      "The number of missing y values is: 0\n"
     ]
    }
   ],
   "source": [
    "# break df into x and y numpy arrays\n",
    "df_y = df.TCL.values\n",
    "df_x = df.drop(['TCL', 'No.'], axis = 1).values\n",
    "\n",
    "\n",
    "# are the two arrays the correct shape?\n",
    "print(df_x.shape, df_y.shape)\n",
    "\n",
    "# Any missing values?\n",
    "print('The number of missing x values is:', np.count_nonzero(np.isnan(df_x)))\n",
    "print('The number of missing y values is:', np.count_nonzero(np.isnan(df_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.91803998e-17  5.83607997e-17  5.10656997e-17 -8.75411995e-17\n",
      " -1.60492199e-16 -8.75411995e-16 -2.91803998e-16 -6.56558996e-17\n",
      " -1.45901999e-17  7.29509996e-17  2.91803998e-17 -1.16721599e-16\n",
      "  7.29509996e-17 -2.91803998e-17  5.83607997e-17  1.16721599e-16\n",
      " -8.75411995e-17  1.02131399e-16 -3.79345198e-16 -2.62623598e-16\n",
      "  2.11557899e-16] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Normalize feature data\n",
    "\n",
    "normX = (df_x - df_x.mean(axis = 0)) / df_x.std(axis = 0)\n",
    "\n",
    "\n",
    "#check our work. Variance should be one and mean should be ~0\n",
    "print(normX.mean(axis = 0), normX.var(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normX, df_y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MAE at alpha of  is: 2.958\n",
      "The test MAE is: 3.601\n",
      "The train RMSE is: 14.449\n",
      "The test RMSE is: 23.291\n",
      "The train R^2 is: 0.09\n",
      "The test R^2 is: 0.01\n"
     ]
    }
   ],
   "source": [
    "#get transformed x matrix\n",
    "x_train_reduced = PCA(n_components= 2).fit_transform(X_train)\n",
    "x_test_reduced = PCA(n_components= 2).fit_transform(X_test)\n",
    "\n",
    "#define ridge regression and fit data\n",
    "rdg = Ridge(alpha= 0.1).fit(x_train_reduced, y_train)\n",
    "\n",
    "#get y predictions\n",
    "y_train_pred = rdg.predict(x_train_reduced)\n",
    "y_test_pred = rdg.predict(x_test_reduced)\n",
    "\n",
    " #MAE values\n",
    "print('The train MAE at alpha of  is: %0.3f' % mean_absolute_error(y_train, y_train_pred))\n",
    "print('The test MAE is: %0.3f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "#RMSE values\n",
    "#MAE values\n",
    "print('The train RMSE is: %0.3f' % mean_squared_error(y_train, y_train_pred))\n",
    "print('The test RMSE is: %0.3f' % mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "#R^2 values\n",
    "print('The train R^2 is: %0.2f' % r2_score(y_train, y_train_pred))\n",
    "print('The test R^2 is: %0.2f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Comment\n",
    "\n",
    "For reference the error values from the previous lab using a Ridge regression without dimensional reduction are\n",
    "\n",
    "* The alpha value used in this regression is 0.1\n",
    "\n",
    "* The train MAE at alpha of  is: 3.806\n",
    "* The test MAE is: 4.651\n",
    "\n",
    "* The train RMSE is: 22.017\n",
    "* The test RMSE is: 34.094\n",
    "\n",
    "* The train R^2 is: -0.39\n",
    "* The test R^2 is: -0.45\n",
    "\n",
    "It can be seen that across all error metrics, adding a dimensional reduction step improves the model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MAE at alpha of  is: 2.908\n",
      "The test MAE is: 3.399\n",
      "The train RMSE is: 14.124\n",
      "The test RMSE is: 21.818\n",
      "The train R^2 is: 0.11\n",
      "The test R^2 is: 0.07\n"
     ]
    }
   ],
   "source": [
    "#get transformed x matrix\n",
    "x_train_reduced = PCA(n_components= 4).fit_transform(X_train)\n",
    "x_test_reduced = PCA(n_components= 4).fit_transform(X_test)\n",
    "\n",
    "#define ridge regression and fit data\n",
    "rdg = Ridge(alpha= 0.1).fit(x_train_reduced, y_train)\n",
    "\n",
    "#get y predictions\n",
    "y_train_pred = rdg.predict(x_train_reduced)\n",
    "y_test_pred = rdg.predict(x_test_reduced)\n",
    "\n",
    " #MAE values\n",
    "print('The train MAE at alpha of  is: %0.3f' % mean_absolute_error(y_train, y_train_pred))\n",
    "print('The test MAE is: %0.3f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "#RMSE values\n",
    "#MAE values\n",
    "print('The train RMSE is: %0.3f' % mean_squared_error(y_train, y_train_pred))\n",
    "print('The test RMSE is: %0.3f' % mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "#R^2 values\n",
    "print('The train R^2 is: %0.2f' % r2_score(y_train, y_train_pred))\n",
    "print('The test R^2 is: %0.2f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Comment\n",
    "\n",
    "The error metrics are *slightly* better when 4 components are used instead of two, but only slight. This suggest that the first two components adaquately capture most of the variation in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MAE at alpha of  is: 2.823\n",
      "The test MAE is: 3.466\n",
      "The train RMSE is: 13.604\n",
      "The test RMSE is: 22.629\n",
      "The train R^2 is: 0.14\n",
      "The test R^2 is: 0.04\n"
     ]
    }
   ],
   "source": [
    "#get transformed x matrix\n",
    "x_train_reduced = PCA(n_components= 8).fit_transform(X_train)\n",
    "x_test_reduced = PCA(n_components= 8).fit_transform(X_test)\n",
    "\n",
    "#define ridge regression and fit data\n",
    "rdg = Ridge(alpha= 0.1).fit(x_train_reduced, y_train)\n",
    "\n",
    "#get y predictions\n",
    "y_train_pred = rdg.predict(x_train_reduced)\n",
    "y_test_pred = rdg.predict(x_test_reduced)\n",
    "\n",
    " #MAE values\n",
    "print('The train MAE at alpha of  is: %0.3f' % mean_absolute_error(y_train, y_train_pred))\n",
    "print('The test MAE is: %0.3f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "#RMSE values\n",
    "#MAE values\n",
    "print('The train RMSE is: %0.3f' % mean_squared_error(y_train, y_train_pred))\n",
    "print('The test RMSE is: %0.3f' % mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "#R^2 values\n",
    "print('The train R^2 is: %0.2f' % r2_score(y_train, y_train_pred))\n",
    "print('The test R^2 is: %0.2f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Comment\n",
    "\n",
    "Similiar to the last comment, the addition of the higher order components does little to improve fit. In this case, with 8 PCs, the test error increases on all metrics, suggesting that 8 out of the max 21 PCs is too many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5\n",
    "\n",
    "Pick 4 principal components for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MAE is: 2.58\n",
      "The test MAE is: 3.34\n",
      "The train RMSE is: 11.35\n",
      "The test RMSE is: 21.91\n",
      "The train R^2 is: 0.28\n",
      "The test R^2 is: 0.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#get transformed x matrix\n",
    "x_train_reduced = PCA(n_components= 4).fit_transform(X_train)\n",
    "x_test_reduced = PCA(n_components= 4).fit_transform(X_test)\n",
    "\n",
    "#define model and fit data\n",
    "mlp = MLPRegressor(hidden_layer_sizes= (6, 6), \\\n",
    "                  max_iter= 1000).fit(x_train_reduced, y_train)\n",
    "\n",
    "#Generate Predicted data set\n",
    "y_train_pred = mlp.predict(x_train_reduced)\n",
    "y_test_pred = mlp.predict(x_test_reduced)\n",
    "\n",
    "#MAE values\n",
    "print('The train MAE is: %0.2f' % mean_absolute_error(y_train, y_train_pred))\n",
    "print('The test MAE is: %0.2f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "#RMSE values\n",
    "print('The train RMSE is: %0.2f' % mean_squared_error(y_train, y_train_pred))\n",
    "print('The test RMSE is: %0.2f' % mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "#R^2 values\n",
    "print('The train R^2 is: %0.2f' % r2_score(y_train, y_train_pred))\n",
    "print('The test R^2 is: %0.2f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Comment\n",
    "\n",
    "The values of error metrics for the model trained on the non-dimensional reduced data set are:\n",
    "\n",
    "* The train MAE is: 1.13\n",
    "* The test MAE is: 1.73\n",
    "\n",
    "* The train RMSE is: 2.77\n",
    "* The test RMSE is: 7.42\n",
    "\n",
    "* The train R^2 is: 0.82\n",
    "* The test R^2 is: 0.68\n",
    "\n",
    "In this case, combining dimension reduction with the neural network results in higher scores in all error metrics and suggests that the model is poorly fit. Given that training and test error are both higher, it is clear that PCA and NN are a poor combination. The likely cause is that the PCA still generates linear features, where as the neural network can handle non-linear features. The main effect that PCA does is discard data that the neural network could have used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6- Pick your favorite\n",
    "\n",
    "Model of choice is Gradient Boosting tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MAE is: 1.40\n",
      "The test MAE is: 3.52\n",
      "The train RMSE is: 3.24\n",
      "The test RMSE is: 24.05\n",
      "The train R^2 is: 0.80\n",
      "The test R^2 is: -0.02\n"
     ]
    }
   ],
   "source": [
    "#get transformed x matrix\n",
    "x_train_reduced = PCA(n_components= 4).fit_transform(X_train)\n",
    "x_test_reduced = PCA(n_components= 4).fit_transform(X_test)\n",
    "\n",
    "\n",
    "#define model\n",
    "gbt = GradientBoostingRegressor().fit(x_train_reduced, y_train)\n",
    "\n",
    "#get prediction arrays for train and test data sets\n",
    "y_train_pred = gbt.predict(x_train_reduced)\n",
    "y_test_pred = gbt.predict(x_test_reduced)\n",
    "\n",
    "#MAE values\n",
    "print('The train MAE is: %0.2f' % mean_absolute_error(y_train, y_train_pred))\n",
    "print('The test MAE is: %0.2f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "#RMSE values\n",
    "#MAE values\n",
    "print('The train RMSE is: %0.2f' % mean_squared_error(y_train, y_train_pred))\n",
    "print('The test RMSE is: %0.2f' % mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "#R^2 values\n",
    "print('The train R^2 is: %0.2f' % r2_score(y_train, y_train_pred))\n",
    "print('The test R^2 is: %0.2f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 Comment\n",
    "\n",
    "The original gradient boosted tree regression had the following scores for the error metrics of interest:\n",
    "\n",
    "* The train MAE is: 0.81\n",
    "* The test MAE is: 1.56\n",
    "\n",
    "* The train RMSE is: 1.22\n",
    "* The test RMSE is: 5.49\n",
    "\n",
    "* The train R^2 is: 0.92\n",
    "* The test R^2 is: 0.77\n",
    "\n",
    "Gradient boosted tree regression is significantly worse when combined with dimensional reduction. Similar to the case of PCA then NN, the gradient boosted tree regression can handle non-linearity and the linear features coming from PCA are only discarding otherwise useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
