{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE1065\n",
    "## Lab 8- Defect Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sklearn packages - model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#sklearn models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#sklearn packages - metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No.</th>\n",
       "      <th>C</th>\n",
       "      <th>Si</th>\n",
       "      <th>Mn</th>\n",
       "      <th>P</th>\n",
       "      <th>S</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Ni</th>\n",
       "      <th>Mo</th>\n",
       "      <th>N</th>\n",
       "      <th>...</th>\n",
       "      <th>Al</th>\n",
       "      <th>Ti</th>\n",
       "      <th>V</th>\n",
       "      <th>B</th>\n",
       "      <th>Th</th>\n",
       "      <th>I</th>\n",
       "      <th>U</th>\n",
       "      <th>Ve</th>\n",
       "      <th>Strain</th>\n",
       "      <th>TCL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.019</td>\n",
       "      <td>17.33</td>\n",
       "      <td>10.62</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.060</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.013</td>\n",
       "      <td>16.95</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.078</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.09</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.001</td>\n",
       "      <td>17.40</td>\n",
       "      <td>11.50</td>\n",
       "      <td>2.88</td>\n",
       "      <td>0.105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.51</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.001</td>\n",
       "      <td>17.55</td>\n",
       "      <td>12.95</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1.54</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.023</td>\n",
       "      <td>16.28</td>\n",
       "      <td>10.15</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>100</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.23</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   No.      C    Si    Mn      P      S     Cr     Ni    Mo      N  ...    Al  \\\n",
       "0    1  0.010  0.48  1.61  0.024  0.019  17.33  10.62  2.09  0.060  ...  0.02   \n",
       "1    2  0.011  0.58  1.06  0.032  0.013  16.95  10.50  2.15  0.078  ...  0.02   \n",
       "2    3  0.010  0.46  1.09  0.021  0.001  17.40  11.50  2.88  0.105  ...  0.02   \n",
       "3    4  0.010  0.51  1.60  0.021  0.001  17.55  12.95  2.76  0.113  ...  0.02   \n",
       "4    5  0.012  0.46  1.54  0.027  0.023  16.28  10.15  2.06  0.098  ...  0.02   \n",
       "\n",
       "    Ti    V    B    Th    I     U    Ve  Strain  TCL  \n",
       "0  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  1.5  \n",
       "1  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  1.1  \n",
       "2  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  0.9  \n",
       "3  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  3.7  \n",
       "4  0.0  0.0  0.0  3.18  100  12.0  4.23     4.0  1.5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load data\n",
    "#read csv\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "#get head\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep and clean data\n",
    "\n",
    "* split into x and y arrays\n",
    "* Check for missing values\n",
    "* normalize x values to zero mean and unit variance\n",
    "* train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(487, 21) (487,)\n",
      "The number of missing x values is: 0\n",
      "The number of missing y values is: 0\n"
     ]
    }
   ],
   "source": [
    "# break df into x and y numpy arrays\n",
    "df_y = df.TCL.values\n",
    "df_x = df.drop(['TCL', 'No.'], axis = 1).values\n",
    "\n",
    "\n",
    "# are the two arrays the correct shape?\n",
    "print(df_x.shape, df_y.shape)\n",
    "\n",
    "# Any missing values?\n",
    "print('The number of missing x values is:', np.count_nonzero(np.isnan(df_x)))\n",
    "print('The number of missing y values is:', np.count_nonzero(np.isnan(df_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.91803998e-17  5.83607997e-17  5.10656997e-17 -8.75411995e-17\n",
      " -1.60492199e-16 -8.75411995e-16 -2.91803998e-16 -6.56558996e-17\n",
      " -1.45901999e-17  7.29509996e-17  2.91803998e-17 -1.16721599e-16\n",
      "  7.29509996e-17 -2.91803998e-17  5.83607997e-17  1.16721599e-16\n",
      " -8.75411995e-17  1.02131399e-16 -3.79345198e-16 -2.62623598e-16\n",
      "  2.11557899e-16] [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Normalize feature data\n",
    "\n",
    "normX = (df_x - df_x.mean(axis = 0)) / df_x.std(axis = 0)\n",
    "\n",
    "\n",
    "#check our work. Variance should be one and mean should be ~0\n",
    "print(normX.mean(axis = 0), normX.var(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(normX, df_y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MAE is: 3.81\n",
      "The test MAE is: 4.65\n",
      "The train RMSE is: 22.02\n",
      "The test RMSE is: 34.10\n"
     ]
    }
   ],
   "source": [
    "# fit linear regression model\n",
    "reg = LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
    "\n",
    "#get prediction arrays for train and test data sets\n",
    "y_train_pred = reg.predict(X_train)\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "#MAE values\n",
    "print('The train MAE is: %0.2f' % mean_absolute_error(y_train, y_train_pred))\n",
    "print('The test MAE is: %0.2f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "#RMSE values\n",
    "#MAE values\n",
    "print('The train RMSE is: %0.2f' % mean_squared_error(y_train, y_train_pred))\n",
    "print('The test RMSE is: %0.2f' % mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2b: Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "The alpha value used in this regression is 0.01\n",
      "The train MAE at alpha of  is: 3.806\n",
      "The test MAE is: 4.651\n",
      "The train RMSE is: 22.017\n",
      "The test RMSE is: 34.096\n",
      "The train R^2 is: -0.39\n",
      "The test R^2 is: -0.45\n",
      "  \n",
      "The alpha value used in this regression is 0.1\n",
      "The train MAE at alpha of  is: 3.806\n",
      "The test MAE is: 4.651\n",
      "The train RMSE is: 22.017\n",
      "The test RMSE is: 34.094\n",
      "The train R^2 is: -0.39\n",
      "The test R^2 is: -0.45\n",
      "  \n",
      "The alpha value used in this regression is 1.5\n",
      "The train MAE at alpha of  is: 3.805\n",
      "The test MAE is: 4.648\n",
      "The train RMSE is: 22.019\n",
      "The test RMSE is: 34.075\n",
      "The train R^2 is: -0.39\n",
      "The test R^2 is: -0.45\n",
      "  \n",
      "The alpha value used in this regression is 2.0\n",
      "The train MAE at alpha of  is: 3.805\n",
      "The test MAE is: 4.647\n",
      "The train RMSE is: 22.020\n",
      "The test RMSE is: 34.070\n",
      "The train R^2 is: -0.39\n",
      "The test R^2 is: -0.45\n",
      "  \n",
      "The alpha value used in this regression is 5.0\n",
      "The train MAE at alpha of  is: 3.803\n",
      "The test MAE is: 4.644\n",
      "The train RMSE is: 22.033\n",
      "The test RMSE is: 34.048\n",
      "The train R^2 is: -0.39\n",
      "The test R^2 is: -0.45\n"
     ]
    }
   ],
   "source": [
    "# alpha values\n",
    "alphas = [0.01, 0.1, 1.5, 2.0, 5.0]\n",
    "\n",
    "for a in alphas:\n",
    "    ridge = Ridge(alpha = a, fit_intercept=False).fit(X_train, y_train)\n",
    "    #get prediction arrays for train and test data sets\n",
    "    y_train_pred = ridge.predict(X_train)\n",
    "    y_test_pred = ridge.predict(X_test)\n",
    "\n",
    "    print('  ')\n",
    "    print('The alpha value used in this regression is', a)\n",
    "    \n",
    "    #MAE values\n",
    "    print('The train MAE at alpha of  is: %0.3f' % mean_absolute_error(y_train, y_train_pred))\n",
    "    print('The test MAE is: %0.3f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "    #RMSE values\n",
    "    #MAE values\n",
    "    print('The train RMSE is: %0.3f' % mean_squared_error(y_train, y_train_pred))\n",
    "    print('The test RMSE is: %0.3f' % mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    #R^2 values\n",
    "    print('The train R^2 is: %0.2f' % r2_score(y_train, y_train_pred))\n",
    "    print('The test R^2 is: %0.2f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2b Comment\n",
    "\n",
    "For the values of alpha suggested, the coefficients are relatively constant and every similar to the least squares regression model. Only as the alpha value is increased to large values (i.e. 10) does the model start to reduce the coefficients towards zero. From the results of alphas, the MAE and RMSE is relatively unchanging across the number of alphas selected, though an alpha value of 5 gives a slightly better training RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2c: Plotting True and Predicted Y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Predicted Test Y Values')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "ridge = Ridge(alpha = 5).fit(X_train, y_train)\n",
    "#get prediction arrays for train and test data sets\n",
    "y_train_pred = ridge.predict(X_train)\n",
    "y_test_pred = ridge.predict(X_test)\n",
    "\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "plt.xlabel('True Test Y Values')\n",
    "plt.ylabel('Predicted Test Y Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3a: Fitting a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MAE is: 1.13\n",
      "The test MAE is: 1.73\n",
      "The train RMSE is: 2.77\n",
      "The test RMSE is: 7.42\n",
      "The train R^2 is: 0.82\n",
      "The test R^2 is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#define model and fit data\n",
    "mlp = MLPRegressor(hidden_layer_sizes= (6, 6), \\\n",
    "                  max_iter= 1000).fit(X_train, y_train)\n",
    "\n",
    "#Generate Predicted data set\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "#MAE values\n",
    "print('The train MAE is: %0.2f' % mean_absolute_error(y_train, y_train_pred))\n",
    "print('The test MAE is: %0.2f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "#RMSE values\n",
    "print('The train RMSE is: %0.2f' % mean_squared_error(y_train, y_train_pred))\n",
    "print('The test RMSE is: %0.2f' % mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "#R^2 values\n",
    "print('The train R^2 is: %0.2f' % r2_score(y_train, y_train_pred))\n",
    "print('The test R^2 is: %0.2f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3a- Comment\n",
    "\n",
    "Considering both MAE and RMSE, the neural network fits the data much better. By inspection, it can be seen in the plot in Part 2c that a the true and predicted y-values depart from linearity, suggesting linear models may be inappropiate and a more flexible model is needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3b: optional 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MAE is: 1.13\n",
      "The test MAE is: 1.94\n",
      "The train RMSE is: 2.48\n",
      "The test RMSE is: 8.17\n",
      "The train R^2 is: 0.84\n",
      "The test R^2 is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#define model and fit data\n",
    "mlp = MLPRegressor(hidden_layer_sizes= (6, 6, 3), \\\n",
    "                  max_iter= 1000).fit(X_train, y_train)\n",
    "\n",
    "#Generate Predicted data set\n",
    "y_train_pred = mlp.predict(X_train)\n",
    "y_test_pred = mlp.predict(X_test)\n",
    "\n",
    "#MAE values\n",
    "print('The train MAE is: %0.2f' % mean_absolute_error(y_train, y_train_pred))\n",
    "print('The test MAE is: %0.2f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "#RMSE values\n",
    "print('The train RMSE is: %0.2f' % mean_squared_error(y_train, y_train_pred))\n",
    "print('The test RMSE is: %0.2f' % mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "#R^2 values\n",
    "print('The train R^2 is: %0.2f' % r2_score(y_train, y_train_pred))\n",
    "print('The test R^2 is: %0.2f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3b- Comment\n",
    "\n",
    "The extra hidden layer leads for overfitting - training error drops, but test error rises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3c: Optional 2 - Grid Search CV\n",
    "\n",
    "Look at the affect of activation function and alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Ian Johnston\\Anaconda3\\envs\\MSE1065\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=MLPRegressor(activation='relu', alpha=0.0001,\n",
       "                                    batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                    early_stopping=False, epsilon=1e-08,\n",
       "                                    hidden_layer_sizes=(100,),\n",
       "                                    learning_rate='constant',\n",
       "                                    learning_rate_init=0.001, max_fun=15000,\n",
       "                                    max_iter=200, momentum=0.9,\n",
       "                                    n_iter_no_change=10,\n",
       "                                    nesterovs_momentum=True, power_t=0.5,\n",
       "                                    random_state=None, shuffle=True,\n",
       "                                    solver='adam', tol=0.0001,\n",
       "                                    validation_fraction=0.1, verbose=False,\n",
       "                                    warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'activation': ('tanh', 'relu'),\n",
       "                         'alpha': (0.0001, 0.01)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "      \n",
    "#specify parameters           \n",
    "parameters = {'activation' : ('tanh', 'relu'), 'alpha': (0.0001, 0.01)}\n",
    "\n",
    "mlp = MLPRegressor()\n",
    "\n",
    "clf = GridSearchCV(mlp, parameters)\n",
    "\n",
    "#fit whole data set that has not been split into train and test\n",
    "clf.fit(normX, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.49168077, 0.46580453, 0.63442168, 0.65769391]),\n",
       " 'std_fit_time': array([0.03361945, 0.01637171, 0.04029428, 0.0931882 ]),\n",
       " 'mean_score_time': array([0.001196  , 0.00159607, 0.00119705, 0.00139527]),\n",
       " 'std_score_time': array([0.00039979, 0.00079803, 0.0003989 , 0.00048936]),\n",
       " 'param_activation': masked_array(data=['tanh', 'tanh', 'relu', 'relu'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_alpha': masked_array(data=[0.0001, 0.01, 0.0001, 0.01],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'tanh', 'alpha': 0.0001},\n",
       "  {'activation': 'tanh', 'alpha': 0.01},\n",
       "  {'activation': 'relu', 'alpha': 0.0001},\n",
       "  {'activation': 'relu', 'alpha': 0.01}],\n",
       " 'split0_test_score': array([0.20775519, 0.24117168, 0.3843086 , 0.31738219]),\n",
       " 'split1_test_score': array([0.45227359, 0.43959259, 0.46645444, 0.45053363]),\n",
       " 'split2_test_score': array([0.48800048, 0.49914261, 0.56139147, 0.53476182]),\n",
       " 'split3_test_score': array([0.6637027 , 0.66142111, 0.6654549 , 0.65678895]),\n",
       " 'split4_test_score': array([0.56822478, 0.56948657, 0.62769198, 0.64084607]),\n",
       " 'mean_test_score': array([0.47599135, 0.48216291, 0.54106028, 0.52006253]),\n",
       " 'std_test_score': array([0.15257782, 0.14137626, 0.10346937, 0.12602574]),\n",
       " 'rank_test_score': array([4, 3, 1, 2])}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.cv_results_\n",
    "\n",
    "#print results\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3c Comment\n",
    "\n",
    "The best model was activation function of 'relu' and a alpha of '0.0001'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Pick a favorite\n",
    "\n",
    "Look at Gradient boosting regressor, as it was the method used in our journal presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MAE is: 0.81\n",
      "The test MAE is: 1.56\n",
      "The train RMSE is: 1.22\n",
      "The test RMSE is: 5.49\n",
      "The train R^2 is: 0.92\n",
      "The test R^2 is: 0.77\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "gbt = GradientBoostingRegressor().fit(X_train, y_train)\n",
    "\n",
    "#get prediction arrays for train and test data sets\n",
    "y_train_pred = gbt.predict(X_train)\n",
    "y_test_pred = gbt.predict(X_test)\n",
    "\n",
    "#MAE values\n",
    "print('The train MAE is: %0.2f' % mean_absolute_error(y_train, y_train_pred))\n",
    "print('The test MAE is: %0.2f' % mean_absolute_error(y_test, y_test_pred))\n",
    "\n",
    "#RMSE values\n",
    "#MAE values\n",
    "print('The train RMSE is: %0.2f' % mean_squared_error(y_train, y_train_pred))\n",
    "print('The test RMSE is: %0.2f' % mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "#R^2 values\n",
    "print('The train R^2 is: %0.2f' % r2_score(y_train, y_train_pred))\n",
    "print('The test R^2 is: %0.2f' % r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Comment\n",
    "\n",
    "Gradient Boosting Regressor for this data set is an excellent model choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
